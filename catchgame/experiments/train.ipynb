{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    os.chdir(os.path.join(os.getcwd(), '../../catchgame/'))\n",
    "except:\n",
    "    print(\"already in directory\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device} is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.dqn.network import QNetworkConv\n",
    "from world import CatchEnv\n",
    "\n",
    "n_actions = 3\n",
    "n_episodes = 1000\n",
    "batch_size = 512\n",
    "\n",
    "CATCH_ENV_NUM_STATES = 4\n",
    "CATCH_ENV_WORLD_SIZE = (84, 84)\n",
    "CATCH_ENV_POSSIBLE_ACTIONS = [0, 1, 2]\n",
    "\n",
    "spatial_size = CATCH_ENV_WORLD_SIZE\n",
    "\n",
    "dqn = QNetworkConv(\n",
    "    in_channels=CATCH_ENV_NUM_STATES, \n",
    "    spatial_size=spatial_size, \n",
    "    output_size=len(CATCH_ENV_POSSIBLE_ACTIONS)\n",
    ").to(device)\n",
    "dqn_target = QNetworkConv(\n",
    "    in_channels=CATCH_ENV_NUM_STATES,\n",
    "    spatial_size=spatial_size,\n",
    "    output_size=len(CATCH_ENV_POSSIBLE_ACTIONS)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84, 84, 4), 0, False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = CatchEnv()\n",
    "env.reset_random()\n",
    "next_state, reward, done = env.step(action=1)\n",
    "next_state.shape, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mo\\anaconda3\\envs\\ml_env\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 84, 84])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Resize(spatial_size),\n",
    "    lambda x: x.unsqueeze(0),\n",
    "    lambda x: x.type(torch.float32),\n",
    "])\n",
    "\n",
    "transforms(next_state).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(dqn.parameters(), lr=1e-4)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "\n",
    "num_episodes = 1000\n",
    "epsilon = 0.8\n",
    "gamma = 0.9\n",
    "epsilon_decay = 0.99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_log = []\n",
    "def log(data: dict):\n",
    "    experiment_log.append(data)\n",
    "    print(\"; \".join([f\"{k}: {v}\" for k, v in data.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0; epsilon: 0.0; reward: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<02:26,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0; mean_reward: 0.1; epsilon: 0.4097383135906444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/1000 [00:00<00:27, 35.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 10; mean_reward: 0.1; epsilon: 0.4097383135906444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1000 [00:00<00:30, 31.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 20; mean_reward: 0.1; epsilon: 0.4097383135906444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 39/1000 [00:01<00:21, 44.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 30; mean_reward: 0.3; epsilon: 0.0904674104977299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 45/1000 [00:01<00:25, 37.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 40; mean_reward: 0.2; epsilon: 0.18944953788996655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 50/1000 [00:03<02:01,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 50; mean_reward: 0.2; epsilon: 0.18944953788996655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 61/1000 [00:10<06:54,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 60; mean_reward: 0.0; epsilon: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 71/1000 [00:15<08:40,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 70; mean_reward: 0.4; epsilon: 0.04599187373045737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 81/1000 [00:22<10:22,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 80; mean_reward: 0.2; epsilon: 0.18944953788996655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 91/1000 [00:28<09:59,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 90; mean_reward: 0.3; epsilon: 0.0904674104977299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [00:35<10:17,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 100; mean_reward: 0.4; epsilon: 0.04599187373045737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 111/1000 [00:41<10:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 110; mean_reward: 0.6; epsilon: 0.017028270857005926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 121/1000 [00:47<09:52,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 120; mean_reward: 0.5; epsilon: 0.02600772686626148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 131/1000 [00:54<09:56,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 130; mean_reward: 0.6; epsilon: 0.017028270857005926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 141/1000 [01:00<09:49,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 140; mean_reward: 0.1; epsilon: 0.4097383135906444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 151/1000 [01:07<09:06,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 150; mean_reward: 0.2; epsilon: 0.18944953788996655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 161/1000 [01:13<09:16,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 160; mean_reward: 0.3; epsilon: 0.0904674104977299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 171/1000 [01:19<09:14,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 170; mean_reward: 0.4; epsilon: 0.04599187373045737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 181/1000 [01:26<09:16,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 180; mean_reward: 0.4; epsilon: 0.04599187373045737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 191/1000 [01:32<09:08,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 190; mean_reward: 0.5; epsilon: 0.02600772686626148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [01:39<09:08,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 200; mean_reward: 0.7; epsilon: 0.01299354119003091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 211/1000 [01:45<08:56,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 210; mean_reward: 0.4; epsilon: 0.04599187373045737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 221/1000 [01:51<07:31,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 220; mean_reward: 0.6; epsilon: 0.017028270857005926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 231/1000 [01:56<07:23,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 230; mean_reward: 0.4; epsilon: 0.04599187373045737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 241/1000 [02:02<07:13,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 240; mean_reward: 0.7; epsilon: 0.01299354119003091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 251/1000 [02:07<07:18,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 250; mean_reward: 0.5; epsilon: 0.02600772686626148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 261/1000 [02:13<07:20,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 260; mean_reward: 0.3; epsilon: 0.0904674104977299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 271/1000 [02:19<07:10,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 270; mean_reward: 0.4; epsilon: 0.04599187373045737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 281/1000 [02:24<07:05,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 280; mean_reward: 0.4; epsilon: 0.04599187373045737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 291/1000 [02:30<07:15,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 290; mean_reward: 0.5; epsilon: 0.02600772686626148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [02:36<07:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 300; mean_reward: 0.7; epsilon: 0.01299354119003091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 311/1000 [02:42<06:58,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 310; mean_reward: 0.9; epsilon: 0.01036602241746411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 321/1000 [02:47<06:52,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 320; mean_reward: 0.5; epsilon: 0.02600772686626148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 331/1000 [02:53<06:53,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 330; mean_reward: 0.2; epsilon: 0.18944953788996655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 341/1000 [02:59<06:29,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 340; mean_reward: 0.6; epsilon: 0.017028270857005926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 351/1000 [03:05<06:59,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 350; mean_reward: 0.6; epsilon: 0.017028270857005926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 361/1000 [03:11<07:07,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 360; mean_reward: 1.0; epsilon: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 371/1000 [03:18<07:12,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 370; mean_reward: 0.6; epsilon: 0.017028270857005926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 381/1000 [03:24<06:57,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 380; mean_reward: 0.6; epsilon: 0.017028270857005926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 390/1000 [03:30<06:22,  1.59it/s]"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "\n",
    "# Define a replay buffer class to store experiences\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "        \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        states, actions, rewards, next_states, done_flags = zip(*batch)\n",
    "        return states, actions, rewards, next_states, done_flags\n",
    "\n",
    "# Initialize the replay buffer\n",
    "replay_buffer = ReplayBuffer(capacity=10000)\n",
    "\n",
    "def evaulate(epsilon=0.0, num_episodes=10):\n",
    "    rewards = []\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset_random()\n",
    "        state = transforms(state)\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        while not done:\n",
    "            if random.uniform(0, 1) < epsilon:\n",
    "                action = random.choice(CATCH_ENV_POSSIBLE_ACTIONS)\n",
    "            else:\n",
    "                q_values = dqn(state.to(device))\n",
    "                action = q_values.argmax().item()\n",
    "            next_state, reward, done = env.step(action)\n",
    "            next_state = transforms(next_state)\n",
    "            episode_reward += reward\n",
    "            state = next_state\n",
    "        rewards.append(episode_reward)\n",
    "    return np.mean(rewards)\n",
    "\n",
    "def sample_epsilon_exponential_decay(min_epsilon=0.01, max_epsilon=0.9, t=0.0, decay_rate=0.5):\n",
    "    I = max_epsilon\n",
    "    E = min_epsilon\n",
    "    s = 10 * decay_rate\n",
    "    theta = (np.exp(-s*t) -1) / (1 - np.exp(-s)) + 1\n",
    "    return (I - E) * theta + E\n",
    "\n",
    "# Define the main training loop\n",
    "best_performance = evaulate(epsilon=0.0, num_episodes=10)\n",
    "log({\"episode\": 0, \"epsilon\": 0.0, \"reward\": best_performance})\n",
    "\n",
    "for episode in tqdm(range(num_episodes)):\n",
    "    # Initialize the environment and state\n",
    "    state = env.reset_random()\n",
    "    state = transforms(state)\n",
    "    done = False\n",
    "    \n",
    "    done_i = 0\n",
    "\n",
    "    while not done:\n",
    "        # Choose an action using an epsilon-greedy policy\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = random.choice(CATCH_ENV_POSSIBLE_ACTIONS)\n",
    "        else:\n",
    "            q_values = dqn(state.to(device))\n",
    "            action = q_values.argmax().item()\n",
    "        \n",
    "        # Take the action and observe the next state and reward\n",
    "        next_state, reward, done = env.step(action)\n",
    "        next_state = transforms(next_state)\n",
    "        \n",
    "        # Add the experience to the replay buffer\n",
    "        replay_buffer.add((state, action, reward, next_state, done))\n",
    "        \n",
    "        # Sample a batch of experiences from the replay buffer\n",
    "        if len(replay_buffer.buffer) > batch_size:\n",
    "            states, actions, rewards, next_states, done_flags = replay_buffer.sample(batch_size)\n",
    "            # (batch, 4, 84, 84)\n",
    "            # [(1, 4, 84, 84), ... ] -> (batch, 4, 84, 84)\n",
    "            \n",
    "            states = torch.cat(states).to(device)\n",
    "            actions = torch.Tensor(actions).type(dtype=torch.int64).to(device)\n",
    "            rewards = torch.Tensor(rewards).to(device)\n",
    "            next_states = torch.cat(next_states).to(device)\n",
    "            done_flags = torch.Tensor(done_flags).to(device)\n",
    "\n",
    "            # Compute the target Q-values using the DDQN algorithm\n",
    "            q_values = dqn(states)\n",
    "            max_actions = q_values.argmax(dim=-1)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                q_values_target = dqn_target(next_states)\n",
    "            q_values_target = q_values_target.gather(1, max_actions.unsqueeze(-1)).squeeze(-1)\n",
    "            q_values_target = rewards + gamma * q_values_target * (1 - done_flags)\n",
    "            \n",
    "            # Compute the current Q-values and the loss\n",
    "            current_q_values = q_values.gather(1, torch.Tensor(actions).unsqueeze(-1)).squeeze(-1)\n",
    "            loss = criterion(current_q_values, q_values_target.detach())\n",
    "            \n",
    "            # Update the DQN network\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update the target network\n",
    "            if done_i % 10 == 0:\n",
    "                dqn_target.load_state_dict(dqn.state_dict())\n",
    "            done_i += 1\n",
    "        \n",
    "        # Update the state\n",
    "        state = next_state\n",
    "\n",
    "    # Evaluate the policy and save the results\n",
    "    if episode % 10 == 0:\n",
    "        mean_reward = evaulate(epsilon=0.0, num_episodes=10)\n",
    "        epsilon = sample_epsilon_exponential_decay(t=mean_reward, decay_rate=0.8)\n",
    "        if mean_reward > best_performance:\n",
    "            best_performance = mean_reward\n",
    "            torch.save(dqn.state_dict(), \"models/dqn_best.pt\")\n",
    "        log({\"episode\": episode, \"mean_reward\": mean_reward, \"epsilon\": epsilon})\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save experiment log where each key is a numpy array\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "runs_folder = \"./runs\"\n",
    "run_name = \"run-\" + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "os.makedirs(runs_folder, exist_ok=True)\n",
    "os.makedirs(os.path.join(runs_folder, run_name), exist_ok=True)\n",
    "keys = experiment_log[0].keys()\n",
    "for key in keys:\n",
    "    np.save(os.path.join(runs_folder, run_name, f\"{key}.npy\"), np.array([log.get(key, None) for log in experiment_log]))\n",
    "\n",
    "df = pd.DataFrame(experiment_log)\n",
    "df.to_csv(os.path.join(runs_folder, run_name, \"log.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and plot all keys into a single plot\n",
    "import matplotlib.pyplot as plt\n",
    "keys = [\"mean_reward\", \"epsilon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load best \n",
    "dqn.load_state_dict(torch.load(\"models/dqn_best.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evluation\n",
    "env = CatchEnv()\n",
    "state = env.reset_random()\n",
    "state = transforms(state)\n",
    "video = []\n",
    "\n",
    "while True:\n",
    "    q_values = dqn(state.to(device))\n",
    "    action = q_values.argmax().item()\n",
    "    next_state, reward, done = env.step(action)\n",
    "    next_state = transforms(next_state)\n",
    "    state = next_state\n",
    "    video.append(next_state.squeeze(0))\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "frames = []\n",
    "video = torch.stack(video)\n",
    "# shape (k iterations, 4 frames, 84, 84)\n",
    "# put side to side resulting in (4 * k, 84, 84) without changing the order\n",
    "video = video.permute(1, 0, 2, 3).reshape(4 * len(video), 84, 84)\n",
    "\n",
    "# video is of shape (time, 84, 84)\n",
    "# make a gif and display it\n",
    "import imageio\n",
    "from IPython.display import Image\n",
    "\n",
    "imageio.mimsave(\"dqn_conv.gif\", 255 * video.cpu().numpy())\n",
    "Image(filename=\"dqn_conv.gif\", format='png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
