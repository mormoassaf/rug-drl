{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "already in directory\n",
      "cuda is available\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.chdir(os.path.join(os.getcwd(), '../../catchgame/'))\n",
    "except:\n",
    "    print(\"already in directory\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device} is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modules.dqn.network import QNetworkConv\n",
    "from world import CatchEnv\n",
    "\n",
    "n_actions = 3\n",
    "n_episodes = 1000\n",
    "batch_size = 32\n",
    "gamma = 0.99\n",
    "eps_start = 1.0\n",
    "eps_end = 0.1\n",
    "eps_decay = 100000\n",
    "target_update = 1000\n",
    "\n",
    "CATCH_ENV_NUM_STATES = 4\n",
    "CATCH_ENV_WORLD_SIZE = (84, 84)\n",
    "CATCH_ENV_POSSIBLE_ACTIONS = [0, 1, 2]\n",
    "\n",
    "spatial_size = CATCH_ENV_WORLD_SIZE\n",
    "qnet = QNetworkConv(\n",
    "    in_channels=CATCH_ENV_NUM_STATES, \n",
    "    spatial_size=spatial_size, \n",
    "    output_size=len(CATCH_ENV_POSSIBLE_ACTIONS)\n",
    ").to(device)\n",
    "qnet(torch.randn(batch_size, CATCH_ENV_NUM_STATES, *spatial_size, device=device)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84, 84, 4), 0, False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = CatchEnv()\n",
    "env.reset_random()\n",
    "next_state, reward, done, = env.step(action=1)\n",
    "\n",
    "next_state.shape, reward, done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
